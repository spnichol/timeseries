google <- read.csv("google_correlate.csv", header=T)
google(names)
names(google)
g.quant() <- google[c(3, 7, 4, 5)]
g.quant <- google[c(3, 7, 4, 5)]
(g.quant)
g.quant <- google[c(3, 7, 4, 5)]
cor(g.quant)
cor.test(g.quant$data_viz, g.quant$degree)
install.packages("Hmisc")
library("Hmisc")
rcorr(as.matrix(g.quant))
reg1 <- lm(data_viz ~
degree + stats_ed + facebook + nba + has_nba + region,
data = google)
summary(reg1)
names(sn)
names(sn)
sn <- read.csv("social_network.csv", header = T)
names(sn)
sn.tab <- table(sn$Gender, sn$Site)
sn.tab
margin.table(sn.tab, 1) # Row marginal frequencies
margin.table(sn.tab, 2) # Column marginal frequencies
round(prop.table(sn.tab), 2)    # cell %
round(prop.table(sn.tab, 1), 2) # row %
round(prop.table(sn.tab, 2), 2) # column %
chisq.test(sn.tab)
("google_correlate.csv", header = T)
names(google)
t.test(google$nba ~ google$has_nba)
names(google)
anova1 <- aov(data_viz ~ region, data = google)
summary(anova1)
anova2a <- aov(data_viz ~
region + stats_ed + region:stats_ed,
data = google)
summary(anova2a)
anova2b <- aov(data_viz ~
region*stats_ed,
data = google)
summary(anova2b)
vector<-c(5,9,1,0)
str(vector)
test <- "test1"
str(test)
getwd()
setwd("C:\Users\Steven\Google Drive\MOT\Fall 2016\BA\Week 1")   #using working directory
setwd("C:\\Users\\Steven\\Google Drive\\MOT\\Fall 2016\\BA\\Week 1")
data<- read.csv("\\Week-01\\zagat.csv", header=TRUE,stringsAsFactors=FALSE)
data<- read.csv("Week-01\\zagat.csv", header=TRUE,stringsAsFactors=FALSE)
names(data)
price<-data$Price
head(data)
str(data)
data$Price[1:10]
mean(data$Price)
quantile(data$Price)
cor(data$Price,data$Food)
summary(data$Price)
zagat<-data
service.sd <- sd(zagat$Service)
service.mean <- mean(zagat$Service)
z <- (zagat$Service-service.mean)/service.sd
zagat.z3 <- subset(zagat, z<3)
zagat.z2 <- subset(zagat, z<2)
zagat.z1 <- subset(zagat, z<1)
dim(zagat)
summary(zagat$Service)
esd(zagat$Service)
dim(zagat)
dim(zagat.z3)
summary(zagat.z3$Service)
sd(zagat.z3$Service)
z <- (zagat$Service-service.mean)/service.sd
zagat.z3 <- subset(zagat, z<3)
zagat.z2 <- subset(zagat, z<2)
zagat.z1 <- subset(zagat, z<1)
# Computing same calculation for data without outliers
dim(zagat)
summary(zagat$Service)
esd(zagat$Service)
dim(zagat.z3)
summary(zagat.z3$Service)
sd(zagat.z3$Service)
dim(zagat.z2)
summary(zagat.z2$Service)
sd(zagat.z2$Service)
dim(zagat.z1)
summary(zagat.z1$Service)
sd(zagat.z1$Service)
sd(zagat$Service)
par(mfrow=c(2,2))
hist(data$Food)
hist(data$Decor, col="blue")
hist(data$Service, col="green")
hist(data$Price, col="red")
head(gold)
library("lubridate")
setwd("C:\\Users\\Steven\\Google Drive\\1. MOT\\1) Fall 2016\\1. BA\\Assignments\\Homework 6")
#read in S&P 500 data
sp <- read.csv("sp.csv", stringsAsFactors=FALSE, header=TRUE)
sp$Date <- as.Date(sp$Date, "%d-%B-%y")
#sort by date, starting with the oldest dates
sp <- sp[order(as.Date(sp$Date, format="%Y/%m/%d", decreasing=FALSE)),]
#sort in decreasing fashion using reverse function (decreasing=TRUE does not work for dates)
sp_descending <- sp[rev(order(as.Date(sp$Date))),]
#read in gold
gold <- read.csv("gold2016.csv", stringsAsFactors=FALSE, header=TRUE)
gold$Date <- as.Date(gold$Date, "%d-%B-%y")
gold <- gold[order(as.Date(gold$Date, format="%y/%m/%d")),]
gold
#create monthly intervals by just third day
gold['day']<- strftime(gold$Date, "%d")
#create snapshot monthly price of Gold on third of month
gold_month <- subset(gold, gold$day == "03")
gold_month['gold_month_price'] <- gold_month$Price
gold_month <- subset(gold_month, select=c("gold_month_price"))
#calculate average monthly price of Gold
gold['day_year'] <- strftime(gold$Date, "%m/%y")
for (i in 1:nrow(gold)) {
submonth <- subset(gold, day_year == day_year[i])
gold$avg_price[i] <- (sum(submonth$Price))/length(submonth$Price)
}
head(gold)
oil <- read.csv("oil2016.csv", stringsAsFactors=FALSE, header=TRUE)
oil$Date <- as.Date(oil$Date, "%d-%B-%y")
oil <- oil[order(as.Date(oil$Date, format="%y/%m/%d")),]
oil['oil'] <- oil$Price
sp['sp'] <- sp$Price
gold['gold'] <- gold$Price
gold['gold_avg'] <-gold$avg_price
timeseries <- merge(oil, sp, by="Date")
timeseries <- merge(timeseries, gold, by="Date")
timeseries <- subset(timeseries, select=c("Date", "oil", "sp", "gold", "gold_avg"))
#unique TS for monthly gold
timeseries_month <- unique(timeseries$gold_avg, incomparables=FALSE)
#create time series
timeseries_all <- subset(timeseries, select=c("oil", "sp", "gold"))
ts.all <- ts(data=timeseries_all)
ts.oil<-ts(timeseries_all$oil)
ts.gold <- ts(timeseries_all$gold)
ts.gold_avg <- ts(timeseries_month)
ts.sp <- ts(timeseries_all$sp)
ts.combo <- cbind(ts.oil, ts.gold_avg)
plot(ts.combo)
ts.oil<-ts(timeseries_all$oil, frequency=12)
ts.combo <- cbind(ts.oil, ts.gold_avg)
ts.gold_avg<-ts(timeseries_month, frequency= 12)
ts.combo <- cbind(ts.oil, ts.gold_avg)
plot(ts.combo)
ts.combo <- cbind(ts.oil, ts.gold_avg)
plot(ts.combo)
plot(ts.combo)
ts.oil
ts.gold_avg
plot.ts(ts.combo)
plot.ts(ts.combo)
plot(ts.combo, plot.type="single",
+ main="Monthly closing prices on SBUX and MSFT",
+ ylab="Adjusted close price",
+ col=c("blue", "red"), lty=1:2)
> legend(1995, 45, legend=c("SBUX","MSFT"), col=c("blue", "red"),
+ lty=1:2)
plot(ts.combo, plot.type="single",
main="Monthly closing prices on SBUX and MSFT",
ylab="Adjusted close price",
col=c("blue", "red"), lty=1:2)
rain <- scan("http://robjhyndman.com/tsdldata/hurst/precip1.dat",skip=1)
head(rain)
str(rain)
rainseries <- ts(rain,start=c(1900), frequency=2)
plot.ts(rainseries)
rainseries.d <- decompose(rainseries)
plot(rainseries.d)
rain.holt <- HoltWinters(rainseries, gamma=FALSE)
rain.holt # to inspect the smoothing results
plot(rain.holt)
library(forecast)
rain.forecasts <- forecast.HoltWinters(rain.holt, h=20)
plot.forecast(rain.forecasts)
```
The forecasts are shown as a blue line, with the 80% prediction intervals as an blue shaded area, and the 95% prediction intervals as a gray shaded area.
Now, lets try it with the time series data `series4` assuming it is monthly.  Notices how the `frequency = 12` affects the time series
```{r}
ts.s4<-ts(timeseries$Series4, start = c(2000), frequency = 12)
ts.s4<-ts(timeseries$Series4, start = c(2000), frequency = 12)
ts.s4<-ts(timeseries6$Series4, start = c(2000), frequency = 12)
ts.s4<-ts(timeseries6$Series4, start = c(2000), frequency = 12)
sp500.sorted<-sp500[order(as.Date(sp500$Date, format="%d/%m/%Y")),]
ts.oil<-ts(timeseries_all$oil, start=c(2010), frequency=12)
ts.gold_avg <- ts(timeseries_month, start=c(2010), frequency=12)
ts.gold_avg <- ts(timeseries_month, start=c(2010), frequency=12)
ts.oil<-ts(timeseries_all$oil, start=c(2010), frequency=12)
ts.combo <- cbind(ts.oil, ts.gold_avg)
plot.ts(ts.combo)
ts.gold_avg <- ts(timeseries_month, start=c(2010), frequency=1)
ts.combo <- cbind(ts.oil, ts.gold_avg)
oil['day_year'] <- strftime(oil$Date, "%m/%y")
oil['avg_price'] <- 0
}
for (i in 1:nrow(oil)) {
submonth <- subset(oil, day_year == day_year[i])
oil$avg_price[i] <- (sum(submonth$Price))/length(submonth$Price)
}
head(oil)
timeseries_month_oil <- unique(oil$avg_price, incomparables=FALSE)
ts.oil_avg <- ts(timeseries_month_oil, start=c(2010), frequenc=1)
ts.combo <- cbind(ts.oil_avg, ts.gold_avg)
plot.ts(ts.combo)
ts.oil_avg <- ts(timeseries_month_oil, start=c(2010), frequency=12)
ts.gold_avg <- ts(timeseries_month, start=c(2010), frequency=12)
ts.combo <- cbind(ts.oil_avg, ts.gold_avg)
plot.ts(ts.combo)
ts.gold_avg.d <- decompose(ts.gold_avg)
plot(ts.gold_avg.d)
ts.oil_avg.d <- decompose(ts.oil_avg)
plot(ts.oil_avg.d)
gold.holt <- HoltWinters(ts.gold_avg.d)
gold.holt <- HoltWinters(ts.gold_avg)
gold.holt <- HoltWinters(ts.gold_avg, GAMMA=FALSE)
library(forecast)
gold.holt <- HoltWinters(ts.gold_avg, gamma=FALSE)
gold.holt <- HoltWinters(ts.gold_avg, gamma=FALSE)
gold.holt
plot(gold.holt)
oil.holt <- HoltWinters(ts.oil_avg, gamma=FALSE)
oil.holt
plot(oil.holt)
